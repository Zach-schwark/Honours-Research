{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Local Creation of Bayesian Network\n",
    "\n",
    "## PC + chi_squared\n",
    "\n",
    "The experimentation and testing of the initial simple Bayesian Network on a smaller dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from Data.DataPreprocessing import DataPreprocessing as myData\n",
    "import pgmpy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "#from Data.DataPreprocessing import DataPreprocessing as myData\n",
    "from pgmpy import estimators\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, precision_score, recall_score, roc_auc_score, balanced_accuracy_score\n",
    "from pgmpy.metrics import correlation_score, log_likelihood_score, structure_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data importing and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zachs\\Documents\\CSHons\\ResearchReport\\Research_Code\\Honours-Research\\Constraint_based_structure_learning\\..\\Data\\DataPreprocessing.py:14: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../Data/accepted_2007_to_2018Q4.csv\", engine='c')\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (23) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (23) found smaller than n_clusters (31). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:278: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:278: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (28) found smaller than n_clusters (31). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (30). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (38) found smaller than n_clusters (43). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (28) found smaller than n_clusters (32). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (34) found smaller than n_clusters (37). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (32) found smaller than n_clusters (34). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (45) found smaller than n_clusters (50). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (43) found smaller than n_clusters (45). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (22) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (26) found smaller than n_clusters (32). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (22) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loaded_data = myData.load_data()\n",
    "#display(loaded_data)\n",
    "data = myData.preprocess_data(loaded_data)\n",
    "train_data, test_data = myData.split_data(data,num_rows = 100)\n",
    "\n",
    "feature_states = myData.get_feature_states(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working for n conditional variables: 1:  20%|██        | 1/5 [07:34<30:16, 454.07s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m est \u001b[38;5;241m=\u001b[39m estimators\u001b[38;5;241m.\u001b[39mPC(data)\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mci_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchi_square\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mnodes())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39medges())\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\estimators\\PC.py:180\u001b[0m, in \u001b[0;36mPC.estimate\u001b[1;34m(self, variant, ci_test, max_cond_vars, return_type, significance_level, n_jobs, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor using Chi Square or Pearsonr, data argument must be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Step 1: Run the PC algorithm to build the skeleton and get the separating sets.\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m skel, separating_sets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_skeleton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mci_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mci_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cond_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_cond_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignificance_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignificance_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskeleton\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m skel, separating_sets\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\estimators\\PC.py:305\u001b[0m, in \u001b[0;36mPC.build_skeleton\u001b[1;34m(self, ci_test, max_cond_vars, significance_level, variant, n_jobs, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39medges():\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m separating_set \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[0;32m    300\u001b[0m         combinations(\u001b[38;5;28mset\u001b[39m(neighbors[u]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m([v]), lim_neighbors),\n\u001b[0;32m    301\u001b[0m         combinations(\u001b[38;5;28mset\u001b[39m(neighbors[v]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m([u]), lim_neighbors),\n\u001b[0;32m    302\u001b[0m     ):\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;66;03m# If a conditioning set exists remove the edge, store the\u001b[39;00m\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;66;03m# separating set and move on to finding conditioning set for next edge.\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mci_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseparating_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43msignificance_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignificance_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    314\u001b[0m             separating_sets[\u001b[38;5;28mfrozenset\u001b[39m((u, v))] \u001b[38;5;241m=\u001b[39m separating_set\n\u001b[0;32m    315\u001b[0m             graph\u001b[38;5;241m.\u001b[39mremove_edge(u, v)\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:94\u001b[0m, in \u001b[0;36mchi_square\u001b[1;34m(X, Y, Z, data, boolean, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchi_square\u001b[39m(X, Y, Z, data, boolean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Chi-square conditional independence test.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    Tests the null hypothesis that X is independent from Y given Zs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpower_divergence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboolean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboolean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:550\u001b[0m, in \u001b[0;36mpower_divergence\u001b[1;34m(X, Y, Z, data, boolean, lambda_, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z_state, df \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mgroupby(Z):\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    549\u001b[0m         c, _, d, _ \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mchi2_contingency(\n\u001b[1;32m--> 550\u001b[0m             \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munstack(Y, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), lambda_\u001b[38;5;241m=\u001b[39mlambda_\n\u001b[0;32m    551\u001b[0m         )\n\u001b[0;32m    552\u001b[0m         chi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    553\u001b[0m         dof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2960\u001b[0m, in \u001b[0;36mGroupBy.size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2902\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2903\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(see_also\u001b[38;5;241m=\u001b[39m_common_see_also)\n\u001b[0;32m   2905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   2906\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m \u001b[38;5;124;03m    Compute group sizes.\u001b[39;00m\n\u001b[0;32m   2908\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2958\u001b[0m \u001b[38;5;124;03m    Freq: MS, dtype: int64\u001b[39;00m\n\u001b[0;32m   2959\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2960\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2961\u001b[0m     dtype_backend: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy_nullable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series):\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:689\u001b[0m, in \u001b[0;36mBaseGrouper.size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m    686\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m    Compute group sizes.\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m     ids, _, ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m\n\u001b[0;32m    690\u001b[0m     out: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ngroups:\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:729\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m--> 729\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[0;32m    732\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:748\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_compressed_codes\u001b[39m(\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    745\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;66;03m# The first returned ndarray may have any signed integer dtype\u001b[39;00m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 748\u001b[0m         group_index \u001b[38;5;241m=\u001b[39m get_group_index(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m compress_group_index(group_index, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort)\n\u001b[0;32m    750\u001b[0m         \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:674\u001b[0m, in \u001b[0;36mBaseGrouper.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]]:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:691\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[1;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:801\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    796\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[1;32m--> 801\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zachs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "est = estimators.PC(data)\n",
    "model = est.estimate(ci_test='chi_square')\n",
    "print(model.nodes())\n",
    "print(model.edges())\n",
    "\n",
    "#scoring_method = estimators.BicScore(data=train_data)\n",
    "#est = estimators.HillClimbSearch(data=train_data, use_cache = True)\n",
    "#estimated_model = est.estimate(\n",
    "#    scoring_method=scoring_method, max_iter=int(1e2))\n",
    "#model = pgmpy.models.BayesianNetwork(estimated_model.edges())\n",
    "#print(model.nodes())\n",
    "#print(model.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_trail_nodes = model.active_trail_nodes('loan_status')['loan_status']\n",
    "active_trail_nodes_list = list(active_trail_nodes)\n",
    "original_nodes = list(model.nodes())\n",
    "for node in original_nodes:\n",
    "    if node not in active_trail_nodes_list:\n",
    "        model.remove_node(node)\n",
    "        \n",
    "\n",
    "nx_graph = nx.DiGraph(model.edges())\n",
    "pos = nx.spring_layout(nx_graph,2)\n",
    "plt.figure(figsize=(5, 5))\n",
    "nx.draw(nx_graph, pos, with_labels=True, node_size=3000, node_color = 'skyblue', edge_color='#424242',font_size=15,font_color='black')\n",
    "plt.title('Learned Bayesian Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_estimator = estimators.BayesianEstimator(model,train_data)\n",
    "parameters = parameter_estimator.get_parameters(n_jobs=6)\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    model.add_cpds(parameters[i])\n",
    "    #print(parameters[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performInference(target_label):\n",
    "    y_pred = []\n",
    "    y_true = []    \n",
    "    testing_evidence_list = myData.get_evidence_list(test_data, target_label=target_label)\n",
    "    inference = VariableElimination(model)\n",
    "    for i in range(len(testing_evidence_list)):\n",
    "        for attribute in list(testing_evidence_list[i].keys()):\n",
    "            if attribute not in model.nodes():\n",
    "                del testing_evidence_list[i][attribute]\n",
    "                \n",
    "    for i in range(len(testing_evidence_list)):\n",
    "        loan_status = inference.map_query([target_label], evidence = testing_evidence_list[i], show_progress= True) \n",
    "        y_pred.append(loan_status[target_label])\n",
    "        y_true.append(test_data[target_label].iloc[i])\n",
    "    \n",
    "    return y_pred, y_true\n",
    "    \n",
    "loan_status_y_pred, loan_status_y_true = performInference('loan_status')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(y_true, y_pred):\n",
    "    data_testing_corr_score = model.simulate(int(1e4))\n",
    "    correlation_score_value = correlation_score(model, data_testing_corr_score, test=\"log_likelihood\", significance_level=0.05)\n",
    "    log_likelihood_score_value = log_likelihood_score(model, data_testing_corr_score)\n",
    "    structure_score_value = structure_score(model, data_testing_corr_score, scoring_method=\"bic\")\n",
    "    print(\"correlation score: \" + str(correlation_score_value))\n",
    "    print(\"Log likelihood score: \" + str(log_likelihood_score_value))\n",
    "    print(\"Structure score: \"+ str(structure_score_value))\n",
    "\n",
    "    accuracy_score_value = accuracy_score(y_true, y_pred)\n",
    "    f1score_value = f1_score(y_true, y_pred, average = None)\n",
    "    precisionScore = precision_score(y_true, y_pred,average = None)\n",
    "    recallScore = recall_score(y_true, y_pred,average = None)\n",
    "    #roc_auc_score_value =  roc_auc_score(y_true, y_pred,average = None)\n",
    "    balanced_accuracy_score_value = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n",
    "\n",
    "    f1_score_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    precision_score_macro = precision_score(y_true, y_pred, average='macro')\n",
    "    recall_score_macro = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    f1_score_weighted = f1_score(y_true, y_pred, average = 'weighted')\n",
    "    precision_score_weighted = precision_score(y_true, y_pred, average = 'weighted')\n",
    "    recall_score_weighted = recall_score(y_true, y_pred, average = 'weighted')\n",
    "\n",
    "    print(\"accuracy score: \"+str(accuracy_score_value))\n",
    "    print(\"f1_score: \"+str(f1score_value))\n",
    "    print(\"precision score: \"+str(precisionScore))\n",
    "    print(\"recall score: \"+str(recallScore))\n",
    "    #print(\"roc auc score: \"+str(roc_auc_score_value))\n",
    "    print(\"balanced_accuracy_score: \" + str(balanced_accuracy_score_value))\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Macro scores:\\n\")\n",
    "    print(\"recall_score_macro: \"+str(recall_score_macro))\n",
    "    print(\"f1_score_macro: \"+str(f1_score_macro))\n",
    "    print(\"precision_score_macro: \"+str(precision_score_macro))\n",
    "    print(\"\\n\")\n",
    "    print(\"Weighted Scores:\\n\")\n",
    "    print(\"recall_score_weighted: \"+str(recall_score_weighted))\n",
    "    print(\"f1_score_weighted: \"+str(f1_score_weighted))\n",
    "    print(\"precision_score_weighted: \"+str(precision_score_weighted))\n",
    "    \n",
    "    \n",
    "testModel(loan_status_y_true, loan_status_y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
